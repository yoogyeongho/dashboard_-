# -*- coding: utf-8 -*-
# ì„±ë™êµ¬ ê°€ë§¹ì  í˜„í™© ëŒ€ì‹œë³´ë“œ (final_df ë‹¨ì¼ ë°ì´í„°ì…‹ ë²„ì „)
# ì‹¤í–‰: streamlit run app_final_dashboard.py

import re
import json
import math
import numpy as np
import pandas as pd
import pydeck as pdk
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from typing import Optional, Tuple, List, Dict
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier


# --------------------------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# --------------------------------------------
st.set_page_config(
    page_title="ì„±ë™êµ¬ ê°€ë§¹ì  í˜„í™© ëŒ€ì‹œë³´ë“œ",
    layout="wide",
    page_icon="ğŸª",
    initial_sidebar_state="collapsed",  # âœ… ê¸°ë³¸ìœ¼ë¡œ ì‚¬ì´ë“œë°” ì ‘ê¸°
)

PRIMARY = "#2563eb"  # blue-600
SAFE = "#16a34a"     # green-600
NORMAL = "#0ea5e9"   # sky-500
CAUTION = "#f59e0b"  # amber-500
DANGER = "#ef4444"   # red-500
GREY = "#6b7280"     # gray-500

st.markdown(
    """
    <style>
    .metric-good .stMetric {background: #ecfdf5; border-radius: 16px; padding: 8px 12px;}
    .metric-warn .stMetric {background: #fffbeb; border-radius: 16px; padding: 8px 12px;}
    .metric-bad  .stMetric {background: #fef2f2; border-radius: 16px; padding: 8px 12px;}
    .metric-neutral .stMetric {background: #f3f4f6; border-radius: 16px; padding: 8px 12px;}
    div[data-baseweb="select"] > div {border-radius: 10px;}
    .sep {margin: 8px 0 20px 0; border-top: 1px solid #e5e7eb;}
    </style>
    """,
    unsafe_allow_html=True,
)

# --------------------------------------------
# ìœ í‹¸(ì§€ë„/ë„í˜•/í¬ë§·/ë…¸ì„ ì§‘ê³„)
# --------------------------------------------
def meters_per_pixel(lat: float, zoom: float) -> float:
    return 156543.03392 * math.cos(math.radians(lat)) / (2 ** zoom)

def _deg_offset(lat: float, dx_m: float, dy_m: float) -> Tuple[float, float]:
    dlat = dy_m / 110_574.0
    dlon = dx_m / (111_320.0 * math.cos(math.radians(lat)))
    return dlon, dlat

def _square_polygon(lon: float, lat: float, half_m: float) -> List[List[float]]:
    dlon, dlat = _deg_offset(lat, half_m, half_m)
    return [
        [lon - dlon, lat - dlat],
        [lon + dlon, lat - dlat],
        [lon + dlon, lat + dlat],
        [lon - dlon, lat + dlat],
    ]

def _triangle_polygon(lon: float, lat: float, half_m: float) -> List[List[float]]:
    dlon_up, dlat_up = _deg_offset(lat, 0.0,  half_m)
    dlon_lw, dlat_lw = _deg_offset(lat, -half_m*0.866, -half_m*0.5)
    dlon_rw, dlat_rw = _deg_offset(lat,  half_m*0.866, -half_m*0.5)
    return [
        [lon + dlon_up, lat + dlat_up],
        [lon + dlon_rw, lat + dlat_rw],
        [lon + dlon_lw, lat + dlat_lw],
    ]

def build_polygon_df(poi_df: pd.DataFrame, size_px: float, lat0: float, zoom: float,
                     shape: str = "triangle",
                     lon_col: str = "ê²½ë„", lat_col: str = "ìœ„ë„") -> pd.DataFrame:
    if poi_df is None or poi_df.empty:
        return poi_df
    mpp = meters_per_pixel(lat0, zoom)
    half_m = float(size_px) * mpp
    polys = []
    for _, r in poi_df.iterrows():
        lon = float(r[lon_col]); lat = float(r[lat_col])
        polygon = _triangle_polygon(lon, lat, half_m) if shape == "triangle" else _square_polygon(lon, lat, half_m)
        row = dict(r); row["polygon"] = polygon
        polys.append(row)
    return pd.DataFrame(polys)

def _fmt_num(v):
    try:
        return f"{float(v):.1f}"
    except Exception:
        return str(v) if v is not None else ""

# --------------------------------------------
# ì¢Œí‘œ/ë°˜ê²½/ì¤‘ë³µ ìœ í‹¸
# --------------------------------------------
def _dedup_points_by_xy(df: pd.DataFrame, lon="ê²½ë„", lat="ìœ„ë„", digits: int = 5) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    key = (df[lon].round(digits).astype(str) + "_" + df[lat].round(digits).astype(str))
    return df.loc[~key.duplicated()].reset_index(drop=True)

def filter_pois_within_radius(poi_df: Optional[pd.DataFrame],
                              stores_df: pd.DataFrame,
                              radius_m: float,
                              lon_col="ê²½ë„", lat_col="ìœ„ë„") -> Optional[pd.DataFrame]:
    if poi_df is None or poi_df.empty or stores_df is None or stores_df.empty:
        return poi_df
    try:
        from sklearn.neighbors import BallTree
        store_coords = np.radians(stores_df[["lat", "lon"]].to_numpy(dtype=float))
        poi_coords   = np.radians(poi_df[[lat_col, lon_col]].to_numpy(dtype=float))
        tree = BallTree(poi_coords, metric="haversine")
        R = 6371000.0
        rad = float(radius_m) / R
        hits = set()
        ind_list = tree.query_radius(store_coords, r=rad)
        for inds in ind_list:
            for j in inds:
                hits.add(int(j))
        if not hits:
            return poi_df.iloc[0:0]
        sub = poi_df.iloc[sorted(list(hits))].copy()
        sub = _dedup_points_by_xy(sub, lon=lon_col, lat=lat_col, digits=5)
        return sub
    except Exception:
        # fallback: ê²½ê³„ë°•ìŠ¤ + í•˜ë²„ì‚¬ì¸
        def haversine(lat1, lon1, lat2, lon2):
            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
            dlat = lat2 - lat1; dlon = lon2 - lon1
            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
            return 2*6371000*np.arcsin(np.sqrt(a))
        keep_idx = set()
        for _, s in stores_df.iterrows():
            lat0, lon0 = float(s["lat"]), float(s["lon"])
            box = poi_df[
                (poi_df[lat_col].between(lat0-0.02, lat0+0.02)) &
                (poi_df[lon_col].between(lon0-0.02, lon0+0.02))
            ]
            if box.empty:
                continue
            d = haversine(box[lat_col].to_numpy(), box[lon_col].to_numpy(), lat0, lon0)
            hits = box.index[d <= radius_m].tolist()
            keep_idx.update(hits)
        if not keep_idx:
            return poi_df.iloc[0:0]
        sub = poi_df.loc[sorted(list(keep_idx))].copy()
        sub = _dedup_points_by_xy(sub, lon=lon_col, lat=lat_col, digits=5)
        return sub

# --------------------------------------------
# ê³µê°„ í•„í„°(GeoJSON í–‰ì •ë™)
# --------------------------------------------
def _filter_points_by_dong_geojson(
    df: Optional[pd.DataFrame],
    selected_dong: Optional[str],
    geojson: Optional[dict]
) -> Optional[pd.DataFrame]:
    if df is None or df.empty or not selected_dong or not geojson:
        return df
    def _dong_name(props: dict) -> Optional[str]:
        if not isinstance(props, dict):
            return None
        keys = ["í–‰ì •ë™", "name", "adm_nm", "ADM_DR_NM", "ADM_NM", "ë™"]
        for k in keys:
            if k in props and props[k]:
                return str(props[k]).strip()
        return None
    try:
        from shapely.geometry import Point, shape
        from shapely.ops import unary_union
        polys = []
        for f in geojson.get("features", []):
            nm = _dong_name(f.get("properties", {}))
            if nm == str(selected_dong).strip():
                try:
                    polys.append(shape(f["geometry"]))
                except Exception:
                    pass
        if not polys:
            return df
        poly = unary_union(polys) if len(polys) > 1 else polys[0]
        poly = poly.buffer(1e-9)
        mask = [poly.intersects(Point(lon, lat)) for lon, lat in zip(df["ê²½ë„"], df["ìœ„ë„"])]
        return df.loc[mask]
    except Exception:
        # geometry íŒŒì‹± ì‹¤íŒ¨ ì‹œ bbox ëŒ€ìš©
        try:
            xs, ys = [], []
            def _collect(coords):
                if coords and isinstance(coords[0], (list, tuple)) and isinstance(coords[0][0], (float, int)):
                    for x, y in coords:
                        xs.append(x); ys.append(y)
                else:
                    for c in coords:
                        _collect(c)
            hit = False
            for f in geojson.get("features", []):
                nm = _dong_name(f.get("properties", {}))
                if nm == str(selected_dong).strip():
                    _collect(f["geometry"]["coordinates"]); hit = True
            if not hit or not xs:
                return df
            minx, maxx = min(xs), max(xs)
            miny, maxy = min(ys), max(ys)
            return df[(df["ê²½ë„"] >= minx) & (df["ê²½ë„"] <= maxx) &
                      (df["ìœ„ë„"] >= miny) & (df["ìœ„ë„"] <= maxy)]
        except Exception:
            return df

# --------------------------------------------
# ë°ì´í„° ë¡œë” (final_df / bus / subway / geojson)
# --------------------------------------------
@st.cache_data(show_spinner=True)
def load_final_df(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    # íƒ€ì… ì •ë¦¬
    for c in ["ê²½ë„","ìœ„ë„","íšŒë³µíƒ„ë ¥ì„±_ì ìˆ˜","ì„ëŒ€ë£Œ ì ìˆ˜","ì†Œë¹„ì•¡ ì ìˆ˜","êµí†µì ‘ê·¼ì„± ì ìˆ˜","ê²½ìŸê³¼ì—´"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    if "íì—…ì—¬ë¶€" in df.columns:
        df["íì—…ì—¬ë¶€"] = pd.to_numeric(df["íì—…ì—¬ë¶€"], errors="coerce").fillna(0).astype(int)
    if "ê¸°ì¤€ë…„ì›”" in df.columns:
        df["ê¸°ì¤€ë…„ì›”"] = df["ê¸°ì¤€ë…„ì›”"].astype(str)
    req = {"ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸","ê²½ë„","ìœ„ë„","í–‰ì •ë™","ì—…ì¢…"}
    missing = req - set(df.columns)
    if missing:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    return df

@st.cache_data(show_spinner=True)
def load_bus(path: str) -> Optional[pd.DataFrame]:
    try:
        df = pd.read_csv(path)
        rename = {}
        if "Xì¢Œí‘œ" in df.columns: rename["Xì¢Œí‘œ"] = "ê²½ë„"
        if "Yì¢Œí‘œ" in df.columns: rename["Yì¢Œí‘œ"] = "ìœ„ë„"
        df = df.rename(columns=rename)
        df["ê²½ë„"] = pd.to_numeric(df["ê²½ë„"], errors="coerce")
        df["ìœ„ë„"] = pd.to_numeric(df["ìœ„ë„"], errors="coerce")
        df = df.dropna(subset=["ê²½ë„", "ìœ„ë„"])
        return df[["ìœ„ë„", "ê²½ë„"] + [c for c in df.columns if c not in ["ìœ„ë„", "ê²½ë„"]]]
    except Exception as e:
        st.warning(f"ë²„ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

@st.cache_data(show_spinner=True)
def load_subway(path: str) -> Optional[pd.DataFrame]:
    try:
        if path.lower().endswith(".xlsx"):
            df = pd.read_excel(path)
        else:
            df = pd.read_csv(path)
        rename = {}
        for c in df.columns:
            cl = str(c).lower().replace(" ", "")
            if cl in ["xì¢Œí‘œ", "x"]:
                rename[c] = "ìœ„ë„"
            if cl in ["yì¢Œí‘œ", "y"]:
                rename[c] = "ê²½ë„"
        df = df.rename(columns=rename)
        df["ê²½ë„"] = pd.to_numeric(df["ê²½ë„"], errors="coerce")
        df["ìœ„ë„"] = pd.to_numeric(df["ìœ„ë„"], errors="coerce")
        df = df.dropna(subset=["ê²½ë„", "ìœ„ë„"])
        return df[["ìœ„ë„", "ê²½ë„"] + [c for c in df.columns if c not in ["ìœ„ë„", "ê²½ë„"]]]
    except Exception as e:
        st.warning(f"ì§€í•˜ì²  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

@st.cache_data(show_spinner=True)
def load_geojson(path: str) -> Optional[dict]:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

# XGBoost ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ 
@st.cache_resource
def train_xgboost_model(df_full):
    """final_df ë°ì´í„°ë¡œ XGBoost ëª¨ë¸ í•™ìŠµ"""
    df_model = df_full.copy()

    # ê¸°ì¤€ë…„ì›” ì²˜ë¦¬ ë° í‘¸ë¦¬ì— ë³€í™˜
    if 'ê¸°ì¤€ë…„ì›”' in df_model.columns:
        df_model['ê¸°ì¤€ë…„ì›”'] = pd.to_datetime(df_model['ê¸°ì¤€ë…„ì›”'].astype(str), format='%Y%m', errors='coerce')
        df_model['ê¸°ì¤€ë…„'] = df_model['ê¸°ì¤€ë…„ì›”'].dt.year.fillna(0).astype(int)
        df_model['ê¸°ì¤€ì›”'] = df_model['ê¸°ì¤€ë…„ì›”'].dt.month.fillna(0).astype(int)
        df_model['month_sin'] = np.sin(2 * np.pi * (df_model['ê¸°ì¤€ì›”'] - 1) / 12).astype('float32')
        df_model['month_cos'] = np.cos(2 * np.pi * (df_model['ê¸°ì¤€ì›”'] - 1) / 12).astype('float32')

    df_model = df_model.drop(columns=['ê¸°ì¤€ë…„ì›”', 'ê¸°ì¤€ì›”'], errors='ignore')

    # Feature ì„ íƒ
    excluded_cols = [
        'ê¸°ì¤€ë…„', 'íì—…ì¼', 'ê°€ë§¹ì ì£¼ì†Œ', 'ê°€ë§¹ì ëª…', 'ê°€ë§¹ì ì§€ì—­', 'ê°ë‹¨ê°€ êµ¬ê°„', 
        'ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ê°œì„¤ì¼', 'ê²½ë„', 'ìœ„ë„', 'ì„ëŒ€ë£Œ ì ìˆ˜', 'ì†Œë¹„ì•¡ ì ìˆ˜', 
        'ê°€ë§¹ì  ì´ìš© ì§ì¥ì¸êµ¬ ìˆ˜', 'ê°€ë§¹ì  ì´ìš© ìƒì£¼ì¸êµ¬ ìˆ˜', 'ê°€ë§¹ì  ì´ìš© ìœ ë™ì¸êµ¬ ìˆ˜',
        'ë…„ì›”', 'ë…„ì›”_str'
    ]
    features = [col for col in df_model.columns if col not in excluded_cols and col != 'íì—…ì—¬ë¶€']
    X_all = df_model[features].fillna(0)
    y_all = df_model['íì—…ì—¬ë¶€']

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    le_dict = {}
    for col in ['ê²½ìŸê³¼ì—´', 'í–‰ì •ë™', 'ì—…ì¢…']:
        if col in X_all.columns and X_all[col].dtype == 'object':
            le = LabelEncoder()
            X_all[col] = le.fit_transform(X_all[col].astype(str))
            le_dict[col] = le

    # 2023ë…„ ë°ì´í„°ë¡œë§Œ í•™ìŠµ (ì—†ìœ¼ë©´ ì „ì²´ë¡œ fallback)
    if 'ê¸°ì¤€ë…„' in df_model.columns and (df_model['ê¸°ì¤€ë…„'] == 2023).any():
        train_mask = df_model['ê¸°ì¤€ë…„'] == 2023
    else:
        train_mask = np.ones(len(df_model), dtype=bool)

    X_train = X_all[train_mask]
    y_train = y_all[train_mask]

    # scale_pos_weight ê³„ì‚°
    pos = np.sum(y_train == 1)
    neg = np.sum(y_train == 0)
    scale_pos_weight = (neg / pos) if pos > 0 else 1.0

    # ëª¨ë¸ í•™ìŠµ
    model = XGBClassifier(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=scale_pos_weight,
        objective="binary:logistic",
        eval_metric="logloss",
        tree_method="hist",
        random_state=42,
        verbosity=0
    )
    model.fit(X_train, y_train)

    return model, features, le_dict


@st.cache_data
def predict_closure_probability(df, _model, features, _le_dict):
    """íì—… í™•ë¥  ì˜ˆì¸¡ (ìºì‹±)"""
    df_pred = df.copy()

    # ê¸°ì¤€ë…„ì›” ì²˜ë¦¬ ë° í‘¸ë¦¬ì— ë³€í™˜
    if 'ê¸°ì¤€ë…„ì›”' in df_pred.columns:
        df_pred['ê¸°ì¤€ë…„ì›”_dt'] = pd.to_datetime(df_pred['ê¸°ì¤€ë…„ì›”'].astype(str), format='%Y%m', errors='coerce')
        df_pred['ê¸°ì¤€ë…„'] = df_pred['ê¸°ì¤€ë…„ì›”_dt'].dt.year.fillna(0).astype(int)
        df_pred['ê¸°ì¤€ì›”'] = df_pred['ê¸°ì¤€ë…„ì›”_dt'].dt.month.fillna(0).astype(int)
        df_pred['month_sin'] = np.sin(2 * np.pi * (df_pred['ê¸°ì¤€ì›”'] - 1) / 12).astype('float32')
        df_pred['month_cos'] = np.cos(2 * np.pi * (df_pred['ê¸°ì¤€ì›”'] - 1) / 12).astype('float32')

    # Feature ì¤€ë¹„(ëˆ„ë½ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€)
    X_pred = pd.DataFrame(index=df_pred.index)
    for feature in features:
        if feature in df_pred.columns:
            X_pred[feature] = df_pred[feature].fillna(0)
        else:
            X_pred[feature] = 0

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    for col, le in _le_dict.items():
        if col in X_pred.columns:
            X_pred[col] = X_pred[col].apply(
                lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else 0
            )

    probabilities = _model.predict_proba(X_pred)[:, 1]
    return probabilities


@st.cache_data
def calculate_warning_grade(df, _model=None, features=None, _le_dict=None, _model_available=True):
    """íì—… í™•ë¥  ê¸°ë°˜ ìœ„ê¸°ê²½ë³´ ë“±ê¸‰ ê³„ì‚° (ìºì‹±)"""
    df = df.copy()

    if _model_available and _model is not None:
        # íì—… í™•ë¥  ì˜ˆì¸¡
        closure_probs = predict_closure_probability(df, _model, features, _le_dict)
        df['íì—…í™•ë¥ '] = closure_probs

        # í•˜ì´ë¸Œë¦¬ë“œ(ì ˆëŒ€+ìƒëŒ€) ì„ê³„ì¹˜
        absolute_thresholds = {'ìœ„í—˜': 0.6, 'ì£¼ì˜': 0.4, 'ê´€ì‹¬': 0.2, 'ì•ˆì •': 0.0}
        percentiles = df['íì—…í™•ë¥ '].quantile([0.75, 0.5, 0.25]).values
        weight_absolute = 0.6
        weight_relative = 0.4
        hybrid_thresholds = [
            weight_absolute * absolute_thresholds['ìœ„í—˜'] + weight_relative * percentiles[0],
            weight_absolute * absolute_thresholds['ì£¼ì˜'] + weight_relative * percentiles[1],
            weight_absolute * absolute_thresholds['ê´€ì‹¬'] + weight_relative * percentiles[2]
        ]

        conditions = [
            df['íì—…í™•ë¥ '] >= hybrid_thresholds[0],
            (df['íì—…í™•ë¥ '] >= hybrid_thresholds[1]) & (df['íì—…í™•ë¥ '] < hybrid_thresholds[0]),
            (df['íì—…í™•ë¥ '] >= hybrid_thresholds[2]) & (df['íì—…í™•ë¥ '] < hybrid_thresholds[1]),
            df['íì—…í™•ë¥ '] < hybrid_thresholds[2]
        ]
        choices = ['ìœ„í—˜', 'ì£¼ì˜', 'ê´€ì‹¬', 'ì•ˆì •']

        df['ìœ„ê¸°ê²½ë³´ë“±ê¸‰'] = np.select(conditions, choices, default='ì•ˆì •')

        # âœ… ëŒ€ì‹œë³´ë“œ ê¸°ì¡´ ì»¬ëŸ¼ëª… í˜¸í™˜: 'ìœ„í—˜ë“±ê¸‰', 'ìœ„í—˜ë„'ë„ ê°™ì´ ë§Œë“¤ì–´ ì¤Œ
        df['ìœ„í—˜ë“±ê¸‰'] = df['ìœ„ê¸°ê²½ë³´ë“±ê¸‰']
        df['ìœ„í—˜ë„']   = (df['íì—…í™•ë¥ '] * 100.0).astype(float)

    else:
        # Fallback: íšŒë³µíƒ„ë ¥ì„± ë¶„ìœ„ ê¸°ë°˜
        percentiles = df['íšŒë³µíƒ„ë ¥ì„±_ì ìˆ˜'].quantile([0.25, 0.5, 0.75]).tolist()
        df['ìœ„ê¸°ê²½ë³´ë“±ê¸‰'] = pd.cut(
            df['íšŒë³µíƒ„ë ¥ì„±_ì ìˆ˜'],
            bins=[-np.inf] + percentiles + [np.inf],
            labels=['ìœ„í—˜', 'ì£¼ì˜', 'ê´€ì‹¬', 'ì•ˆì •']
        )
        df['ìœ„í—˜ë“±ê¸‰'] = df['ìœ„ê¸°ê²½ë³´ë“±ê¸‰']
        df['ìœ„í—˜ë„']   = 100.0 - pd.to_numeric(df.get('íšŒë³µíƒ„ë ¥ì„±_ì ìˆ˜', 50), errors='coerce').fillna(50)

    return df
    

# --------------------------------------------
# ìŠ¤ëƒ…ìƒ·(ë§¤ì¥ë³„ 'ìµœê·¼' 1í–‰ ì„ íƒ) + ìœ„í—˜ë„/ë“±ê¸‰
# --------------------------------------------
def make_latest_snapshot(df: pd.DataFrame) -> pd.DataFrame:
    work = df.copy()
    if "ê¸°ì¤€ë…„ì›”" in work.columns:
        # YYYY-MM or YYYYMM ëª¨ë‘ ì²˜ë¦¬
        try:
            work["_ym"] = work["ê¸°ì¤€ë…„ì›”"].astype(str).str.replace("-","", regex=False).astype(int)
        except Exception:
            work["_ym"] = pd.to_numeric(work["ê¸°ì¤€ë…„ì›”"], errors="coerce")
        work = work.sort_values(["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸","_ym"])
        snap = work.groupby("ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸", as_index=False).tail(1).copy()
    else:
        # ê¸°ì¤€ë…„ì›” ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ë‹ˆí¬ ìµœê·¼ í•œ ì¤„ ê°€ì •
        snap = work.drop_duplicates(subset=["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"], keep="last").copy()

    # # íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜ -> ìœ„í—˜ë„/ë“±ê¸‰
    snap["íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜"] = pd.to_numeric(snap.get("íšŒë³µíƒ„ë ¥ì„±_ì ìˆ˜", np.nan), errors="coerce")
    # s = snap["íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜"].dropna()
    # if len(s) >= 10:
    #     q1, q3 = np.percentile(s, [25, 75])
    #     iqr = q3 - q1
    #     low_out = q1 - 1.5 * iqr
    #     high_out = q3 + 1.5 * iqr
    #     def risk_grade(v: float) -> str:
    #         if np.isnan(v): return "ë‚®ìŒ"
    #         if v <= low_out: return "ìœ„í—˜"
    #         elif v <= q1: return "ì£¼ì˜"
    #         elif v <= q3: return "ë³´í†µ"
    #         elif v <= high_out: return "ì•ˆì „"
    #         else: return "ë§¤ìš°ì•ˆì „"
    # else:
    #     def risk_grade(v: float) -> str:
    #         if np.isnan(v): return "ë‚®ìŒ"
    #         if v < 25: return "ìœ„í—˜"
    #         elif v < 50: return "ì£¼ì˜"
    #         elif v < 75: return "ë³´í†µ"
    #         else: return "ì•ˆì „"

    # snap["ìœ„í—˜ë“±ê¸‰"] = snap["íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜"].apply(risk_grade)
    # snap["ìœ„í—˜ë„"] = 100.0 - snap["íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜"].fillna(50.0)

    # ì¢Œí‘œ ìˆ«ìí™”/ê²°ì¸¡ ì œê±°
    snap["lon"] = pd.to_numeric(snap["ê²½ë„"], errors="coerce")
    snap["lat"] = pd.to_numeric(snap["ìœ„ë„"], errors="coerce")
    snap = snap.dropna(subset=["lon","lat"])
    return snap

# --------------------------------------------
# KPI ê³„ì‚°
# --------------------------------------------
def kpi_summary(df_snapshot: pd.DataFrame) -> Dict[str, float]:
    total = len(df_snapshot)
    pr_caution = float((df_snapshot["ìœ„í—˜ë“±ê¸‰"].isin(["ì£¼ì˜","ìœ„í—˜"]).mean()) * 100.0) if "ìœ„í—˜ë“±ê¸‰" in df_snapshot else np.nan
    closed_rate = float((df_snapshot["íì—…ì—¬ë¶€"] == 1).mean() * 100.0) if "íì—…ì—¬ë¶€" in df_snapshot else np.nan
    mean_res = float(df_snapshot["íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜"].mean()) if "íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜" in df_snapshot else np.nan
    return {
        "ì „ì²´ ê°€ë§¹ì  ìˆ˜": total,
        "ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘(%)": pr_caution,
        "íì—… ë§¤ì¥ ë¹„ì¤‘(%)": closed_rate,
        "í‰ê·  íšŒë³µíƒ„ë ¥ì„±": mean_res,
    }

# --------------------------------------------
# ì‚¬ì´ë“œë°”
# --------------------------------------------
# with st.sidebar:
#     st.header("ğŸ“ ë°ì´í„° ê²½ë¡œ")
#     final_path  = st.text_input("final_df: final_df.zip", value="final_df.zip")
#     bus_path    = st.text_input("ë²„ìŠ¤: merged_bus_data ìµœì¢…ver.csv", value="merged_bus_data ìµœì¢…ver.csv")
#     subway_path = st.text_input("ì§€í•˜ì² : ì„±ë™êµ¬ ë‚´ ì—­ì‚¬ ë° ì¸ê·¼ ì—­ ì •ì œëœ íŒŒì¼.xlsx", value="ì„±ë™êµ¬ ë‚´ ì—­ì‚¬ ë° ì¸ê·¼ ì—­ ì •ì œëœ íŒŒì¼.xlsx")
#     geojson_path= st.text_input("í–‰ì •ë™ GeoJSON (ì„ íƒ)", value="seongdong_í–‰ì •ë™.geojson")
#     st.caption("ê²½ë¡œê°€ ë‹¤ë¥´ë©´ ìˆ˜ì •í•˜ì„¸ìš”. ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ì‹œ í•´ë‹¹ ë ˆì´ì–´ëŠ” ìë™ìœ¼ë¡œ ìˆ¨ê¹€ ì²˜ë¦¬ë©ë‹ˆë‹¤.")

#     show_bus = st.checkbox("ë²„ìŠ¤ ì •ë¥˜ì¥ í‘œì‹œ", value=True, key="opt_bus")
#     show_subway = st.checkbox("ì§€í•˜ì²  ì—­ í‘œì‹œ", value=True, key="opt_subway")

#     st.markdown("---")
#     st.subheader("ğŸ—ºï¸ ë§ˆì»¤ í¬ê¸° ì„¤ì •")
#     size_mode = st.selectbox("ë§ˆì»¤ í¬ê¸° ëª¨ë“œ", ["ê³ ì •", "ìœ„í—˜ë„ ë¹„ë¡€"], index=0, key="size_mode")
#     marker_px = st.slider("ê¸°ë³¸ ë§ˆì»¤ í¬ê¸°(í”½ì…€)", 2, 20, 6, key="marker_px")
#     marker_min = st.slider("ìµœì†Œ í¬ê¸°(ë¹„ë¡€)", 2, 16, 3, key="marker_min")
#     marker_max = st.slider("ìµœëŒ€ í¬ê¸°(ë¹„ë¡€)", 6, 28, 8, key="marker_max")
# --------------------------------------------
# Config (ì‚¬ì´ë“œë°” ì œê±° : ê³ ì •ê°’)
# --------------------------------------------
final_path   = "final_df.zip"
bus_path     = "merged_bus_data ìµœì¢…ver.csv"
subway_path  = "ì„±ë™êµ¬ ë‚´ ì—­ì‚¬ ë° ì¸ê·¼ ì—­ ì •ì œëœ íŒŒì¼.xlsx"
geojson_path = "seongdong_í–‰ì •ë™.geojson"
# ë ˆì´ì–´ í‘œì‹œ ì˜µì…˜
show_bus    = True
show_subway = True
# ë§ˆì»¤ í¬ê¸° ì˜µì…˜
size_mode  = "ê³ ì •"   # "ê³ ì •" ë˜ëŠ” "ìœ„í—˜ë„ ë¹„ë¡€"
marker_px  = 6
marker_min = 3
marker_max = 8

# --------------------------------------------
# ë°ì´í„° ì ì¬
# --------------------------------------------
final_df = load_final_df(final_path)
bus_df = load_bus(bus_path)
subway_df = load_subway(subway_path)
geojson = load_geojson(geojson_path)

# ğŸ‘‰ ëª¨ë¸ í•™ìŠµ (ìºì‹±ë¨)
model, model_features, model_le_dict = train_xgboost_model(final_df)

# --------------------------------------------
# í—¤ë”/íƒ€ì´í‹€
# --------------------------------------------
st.title("ğŸª ì„±ë™êµ¬ ê°€ë§¹ì  í˜„í™© ëŒ€ì‹œë³´ë“œ")
st.markdown('<div class="sep"></div>', unsafe_allow_html=True)

# --------------------------------------------
# ìŠ¤ëƒ…ìƒ· ìƒì„±(ìµœì‹ ì›” ê¸°ì¤€ ë§¤ì¥ 1í–‰)
# --------------------------------------------
snapshot = make_latest_snapshot(final_df)
snapshot = calculate_warning_grade(snapshot, _model=model, features=model_features, _le_dict=model_le_dict, _model_available=True)


# --------------------------------------------
# í•„í„° ì˜ì—­ (í–‰ì •ë™/ì—…ì¢…)
# --------------------------------------------
col_f1, col_f2 = st.columns([1,1])

with col_f1:
    dong_opts = ["(ì „ì²´)"] + sorted(snapshot["í–‰ì •ë™"].dropna().astype(str).unique().tolist())
    selected_dong = st.selectbox("ì§€ì—­(í–‰ì •ë™)", options=dong_opts)
    if selected_dong == "(ì „ì²´)":
        selected_dong = None

with col_f2:
    if selected_dong:
        cats = sorted(snapshot[snapshot["í–‰ì •ë™"]==selected_dong]["ì—…ì¢…"].dropna().unique().tolist())
    else:
        cats = sorted(snapshot["ì—…ì¢…"].dropna().unique().tolist())
    selected_category = st.selectbox("ì—…ì¢…", options=["(ì „ì²´)"] + cats)
    if selected_category == "(ì „ì²´)":
        selected_category = None

# í•„í„° ì ìš©
filtered = snapshot.copy()
if selected_dong:
    filtered = filtered[filtered["í–‰ì •ë™"] == selected_dong]
if selected_category:
    filtered = filtered[filtered["ì—…ì¢…"] == selected_category]

# --------------------------------------------
# KPI ì„¹ì…˜ (ì „ì²´ KPI)
# --------------------------------------------
st.subheader("ğŸ“Š KPI")
# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.kpi-card {
    border: 2px solid #E5E7EB;
    border-radius: 12px;
    padding: 16px;
    text-align: center;
    background-color: #F9FAFB;
    box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}
.kpi-title {
    font-weight: 600;
    font-size: 0.9rem;
    color: #374151;
    margin-bottom: 6px;
}
.kpi-value {
    font-weight: 700;
    font-size: 1.4rem;
    color: #111827;
}
</style>
""", unsafe_allow_html=True)
col1, col2, col3, col4 = st.columns(4)
all_kpi = kpi_summary(snapshot)
col1.markdown(f"""
<div class="kpi-card">
  <div class="kpi-title">ì „ì²´ ê°€ë§¹ì  ìˆ˜</div>
  <div class="kpi-value">{all_kpi['ì „ì²´ ê°€ë§¹ì  ìˆ˜']:,}</div>
</div>
""", unsafe_allow_html=True)
col2.markdown(f"""
<div class="kpi-card">
  <div class="kpi-title">ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘</div>
  <div class="kpi-value">{all_kpi['ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘(%)']:.1f}%</div>
</div>
""", unsafe_allow_html=True)
col3.markdown(f"""
<div class="kpi-card">
  <div class="kpi-title">íì—… ë§¤ì¥ ë¹„ì¤‘</div>
  <div class="kpi-value">{all_kpi['íì—… ë§¤ì¥ ë¹„ì¤‘(%)']:.1f}%</div>
</div>
""", unsafe_allow_html=True)
col4.markdown(f"""
<div class="kpi-card">
  <div class="kpi-title">í‰ê·  íšŒë³µíƒ„ë ¥ì„±</div>
  <div class="kpi-value">{all_kpi['í‰ê·  íšŒë³µíƒ„ë ¥ì„±']:.1f}</div>
</div>
""", unsafe_allow_html=True)
# --------------------------------------------
# íƒ€ê²Ÿ KPI (í•„í„° ë°˜ì˜)
# --------------------------------------------
st.subheader("ğŸ¯ íƒ€ê²Ÿ KPI")
colf1, colf2, colf3, colf4 = st.columns(4)
if filtered.empty or (selected_dong is None and selected_category is None):
    for c, title in zip([colf1, colf2, colf3, colf4],
                        ["ì„ íƒ ê°€ë§¹ì  ìˆ˜", "ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘", "íì—… ë§¤ì¥ ë¹„ì¤‘", "í‰ê·  íšŒë³µíƒ„ë ¥ì„±"]):
        c.markdown(f"""
        <div class="kpi-card">
          <div class="kpi-title">{title}</div>
          <div class="kpi-value">-</div>
        </div>
        """, unsafe_allow_html=True)
else:
    k = kpi_summary(filtered)
    vals = [
        f"{k['ì „ì²´ ê°€ë§¹ì  ìˆ˜']:,}",
        f"{k['ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘(%)']:.1f}%",
        f"{k['íì—… ë§¤ì¥ ë¹„ì¤‘(%)']:.1f}%",
        f"{k['í‰ê·  íšŒë³µíƒ„ë ¥ì„±']:.1f}"
    ]
    for c, title, val in zip(
        [colf1, colf2, colf3, colf4],
        ["ì„ íƒ ê°€ë§¹ì  ìˆ˜", "ì£¼ì˜/ìœ„í—˜ ë¹„ì¤‘", "íì—… ë§¤ì¥ ë¹„ì¤‘", "í‰ê·  íšŒë³µíƒ„ë ¥ì„±"],
        vals
    ):
        c.markdown(f"""
        <div class="kpi-card">
          <div class="kpi-title">{title}</div>
          <div class="kpi-value">{val}</div>
        </div>
        """, unsafe_allow_html=True)
st.markdown('<div class="sep"></div>', unsafe_allow_html=True)
# --------------------------------------------
# ì§€ë„ ì„¹ì…˜ (pydeck) - ê¸°ì¡´ ë¡œì§ ìœ ì§€
# --------------------------------------------
st.subheader("ğŸ—ºï¸ ê°€ë§¹ì  ë¶„í¬ ì§€ë„")

map_df = filtered.copy()
if map_df.empty:
    st.info("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ìƒ‰ìƒ
    color_map = {
    "ìœ„í—˜": (214, 39, 40),
    "ì£¼ì˜": (255, 127, 0),
    "ê´€ì‹¬": (255, 191, 0),
    "ì•ˆì •": (56, 168, 0),
}

    def _rgb_tuple(grade):
        t = color_map.get(str(grade), (120,120,120))
        return [int(t[0]), int(t[1]), int(t[2])]
    rgb = np.array([_rgb_tuple(g) for g in map_df["ìœ„í—˜ë“±ê¸‰"].astype(object).tolist()], dtype=int)
    map_df[["r","g","b"]] = rgb
    map_df["a"] = 200

    if size_mode == "ê³ ì •":
        map_df["pt_size"] = int(marker_px)
    else:
        _risk = pd.to_numeric(map_df.get("ìœ„í—˜ë„", np.nan), errors="coerce").fillna(0.0).clip(0, 100)
        map_df["pt_size"] = (_risk / 100.0) * (marker_max - marker_min) + marker_min
        map_df["pt_size"] = map_df["pt_size"].astype(float)

# ê°€ë§¹ì  íˆ´íŒ(í…ìŠ¤íŠ¸)
if not map_df.empty:
    def _mk_store_tip(r):
        # íì—…ì—¬ë¶€ â†’ ì´ë¦„ ì˜†ì— í‘œê¸°
        closed_raw = r.get('íì—…ì—¬ë¶€', None)
        try:
            status = "íì—…" if int(closed_raw) == 1 else "ì˜ì—…"
        except Exception:
            status = "" if closed_raw is None else str(closed_raw)

        name = str(r.get('ê°€ë§¹ì ëª…', ''))
        # í•„ìš”ì‹œ ì˜ì—…ì¼ ë• í‘œì‹œ ì•ˆ í•˜ë ¤ë©´ ì•„ë˜ í•œ ì¤„ì„: name_line = f"{name}" if status != "íì—…" else f"{name} (íì—…)"
        name_line = f"{name}" if not status else f"{name} ({status})"

        lines = [
            name_line,
            f"{r.get('ì—…ì¢…','')} / {r.get('í–‰ì •ë™','')}",
            f"íšŒë³µíƒ„ë ¥ì„±: {_fmt_num(r.get('íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜'))} Â· "
            f"ìœ„í—˜ë„: {_fmt_num(r.get('ìœ„í—˜ë„'))} ({r.get('ìœ„í—˜ë“±ê¸‰','')})",
            f"ê³ ê°ë‹¤ì–‘ì„±: {_fmt_num(r.get('ê³ ê°ë‹¤ì–‘ì„±_ì ìˆ˜'))} Â· "
            f"ê³ ê°ì¸êµ¬ ì í•©ë„: {_fmt_num(r.get('ê³ ê°ì¸êµ¬_ì í•©ë„_ì ìˆ˜'))}",
            f"ì„ëŒ€ë£ŒëŒ€ë¹„ë§¤ì¶œ: {_fmt_num(r.get('ì„ëŒ€ë£ŒëŒ€ë¹„ë§¤ì¶œ_ì ìˆ˜'))} Â· "
            f"ê°ë‹¨ê°€ ì•ˆì •ì„±: {_fmt_num(r.get('ê°ë‹¨ê°€_ì•ˆì •ì„±_ì ìˆ˜'))}",
            f"ê°€ë§¹ì ì…ì§€ì ìˆ˜: {_fmt_num(r.get('ê°€ë§¹ì ì…ì§€ì ìˆ˜'))}",
        ]
        return "\n".join(lines)

    map_df["tooltip"] = map_df.apply(_mk_store_tip, axis=1)



    # ì´ˆê¸° ë·°
    init_lat = float(map_df["lat"].mean())
    init_lng = float(map_df["lon"].mean())
    view_state = pdk.ViewState(latitude=init_lat, longitude=init_lng, zoom=12.5, pitch=0)

    # ë ˆì´ì–´: ê°€ë§¹ì 
    layers = [
        pdk.Layer(
            "ScatterplotLayer",
            data=map_df,
            get_position='[lon, lat]',
            get_fill_color='[r, g, b, a]',
            get_radius='pt_size',
            radiusUnits='pixels',
            radiusMinPixels=1,
            radiusMaxPixels=int(marker_max) + 4,
            stroked=True,
            get_line_color=[0, 0, 0, 120],
            lineWidthMinPixels=1,
            pickable=True,
            auto_highlight=True,
        )
    ]

    # ------------------------------------------------------------
    # ë²„ìŠ¤/ì§€í•˜ì²  í‘œì‹œ ëŒ€ìƒ ë§Œë“¤ê¸°
    #   - í•„í„° ì—†ìŒ(í–‰ì •ë™/ì—…ì¢… ëª¨ë‘ ì „ì²´): ì „ì²´ ë°ì´í„° ê·¸ëŒ€ë¡œ í‘œì‹œ
    #   - í•„í„° ìˆìŒ(í–‰ì •ë™ ë˜ëŠ” ì—…ì¢… ì„ íƒ): ê¸°ì¡´ ê·œì¹™ ìœ ì§€
    #       Â· í–‰ì •ë™ ì„ íƒ ì‹œ GeoJSON êµì§‘í•©
    #       Â· ê°€ë§¹ì  ë°˜ê²½ í•„í„°(ë²„ìŠ¤ 400m, ì§€í•˜ì²  1000m)
    # ------------------------------------------------------------
    is_filtered = bool(selected_dong or selected_category)

    # 1) ê¸°ë³¸ í›„ë³´ ì§‘í•©
    if selected_dong and geojson is not None:
        # í–‰ì •ë™ì„ ì„ íƒí•œ ê²½ìš°ì—ë§Œ GeoJSON êµì§‘í•© ì ìš©
        bus_df_for_map    = _filter_points_by_dong_geojson(bus_df, selected_dong, geojson)
        subway_df_for_map = _filter_points_by_dong_geojson(subway_df, selected_dong, geojson)
    else:
        # í•„í„°ê°€ ì—†ê±°ë‚˜(ì „ì²´), GeoJSONì´ ì—†ìœ¼ë©´ ì›ë³¸ ì „ì²´
        bus_df_for_map    = bus_df.copy() if bus_df is not None else None
        subway_df_for_map = subway_df.copy() if subway_df is not None else None

    # 2) ë°˜ê²½ í•„í„°ëŠ” "í•„í„°ê°€ í™œì„±í™”ëœ ê²½ìš°"ì—ë§Œ ì ìš©
    if is_filtered:
        if show_bus and bus_df_for_map is not None and not bus_df_for_map.empty:
            bus_df_for_map = filter_pois_within_radius(
                bus_df_for_map,
                map_df[["lat","lon"]],
                radius_m=400.0
            )
        if show_subway and subway_df_for_map is not None and not subway_df_for_map.empty:
            subway_df_for_map = filter_pois_within_radius(
                subway_df_for_map,
                map_df[["lat","lon"]],
                radius_m=1000.0
            )
    # í•„í„°ê°€ ë¹„í™œì„±í™”(ì „ì²´ ë³´ê¸°)ë©´ ë°˜ê²½ í•„í„°ë¥¼ ê±´ë„ˆë›´ë‹¤ â†’ ì „ì²´ ê·¸ëŒ€ë¡œ í‘œì‹œ


    # ë²„ìŠ¤ íˆ´íŒ/ë„í˜•
    if show_bus and bus_df_for_map is not None and not bus_df_for_map.empty:
        for col in ["ê°„ì„ ","ì§€ì„ ","ìˆœí™˜","ë§ˆì„"]:
            if col not in bus_df_for_map.columns:
                bus_df_for_map[col] = ""
        def _find_list_col(df, key):
            patterns = ["ë…¸ì„ ", "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "list", "routes"]
            cands = [c for c in df.columns if (key in str(c)) and any(p in str(c) for p in patterns)]
            return sorted(cands, key=len, reverse=True)[0] if cands else None
        list_cols = {k:_find_list_col(bus_df_for_map, k) for k in ["ê°„ì„ ","ì§€ì„ ","ìˆœí™˜","ë§ˆì„"]}
        def _route_count(cell):
            if cell is None or (isinstance(cell, float) and np.isnan(cell)): return 0
            s = str(cell).strip()
            if not s or s in ["-","nan","None"]: return 0
            parts = re.split(r"[,\s;/|Â·\[\]\(\)\'\"]+|\n|\r", s)
            parts = [p for p in parts if p]
            return len(parts)
        def _count_for_key(df, key):
            list_col = list_cols.get(key)
            base_col = key if key in df.columns else None
            if list_col:
                return df[list_col].apply(_route_count)
            if base_col:
                ser = pd.to_numeric(df[base_col], errors="coerce")
                if ser.notna().any():
                    if ser.max() <= 1: return ser.fillna(0).astype(int)
                    return ser.fillna(0).astype(int)
                return df[base_col].apply(_route_count)
            return pd.Series(0, index=df.index, dtype=int)
        bus_df_for_map["_n_ê°„ì„ "] = _count_for_key(bus_df_for_map, "ê°„ì„ ")
        bus_df_for_map["_n_ì§€ì„ "] = _count_for_key(bus_df_for_map, "ì§€ì„ ")
        bus_df_for_map["_n_ìˆœí™˜"] = _count_for_key(bus_df_for_map, "ìˆœí™˜")
        bus_df_for_map["_n_ë§ˆì„"] = _count_for_key(bus_df_for_map, "ë§ˆì„")
        total_col = None
        for c in bus_df_for_map.columns:
            if any(k in str(c) for k in ["ì´ë…¸ì„ ", "ë…¸ì„ ìˆ˜"]):
                total_col = c; break
        if total_col:
            bus_df_for_map["_n_total"] = pd.to_numeric(bus_df_for_map[total_col], errors="coerce").fillna(0).astype(int)
        else:
            bus_df_for_map["_n_total"] = bus_df_for_map[["_n_ê°„ì„ ","_n_ì§€ì„ ","_n_ìˆœí™˜","_n_ë§ˆì„"]].sum(axis=1)

        if "ì •ë¥˜ì†Œëª…_x" in bus_df_for_map.columns:
            name_col = "ì •ë¥˜ì†Œëª…_x"
        elif "ì •ë¥˜ì†Œëª…" in bus_df_for_map.columns:
            name_col = "ì •ë¥˜ì†Œëª…"
        else:
            name_col = "_tmp_name"; bus_df_for_map[name_col] = "ë²„ìŠ¤ì •ë¥˜ì¥"

        def _mk_bus_tip(r):
            return (f"ğŸšŒ {r.get(name_col,'')}\n"
                    f"ê°„ì„  {int(r.get('_n_ê°„ì„ ',0))} Â· "
                    f"ì§€ì„  {int(r.get('_n_ì§€ì„ ',0))} Â· "
                    f"ìˆœí™˜ {int(r.get('_n_ìˆœí™˜',0))} Â· "
                    f"ë§ˆì„ {int(r.get('_n_ë§ˆì„',0))} "
                    f"(ì´ {int(r.get('_n_total',0))})")
        bus_df_for_map["tooltip"] = bus_df_for_map.apply(_mk_bus_tip, axis=1)

        # í¬ê¸°: ê°€ë§¹ì  ëŒ€ë¹„ ì‘ê²Œ
        poi_px = int(np.clip((map_df["pt_size"].median() if ("pt_size" in map_df.columns and not map_df["pt_size"].empty) else marker_px), 6, 32))
        poi_px_small = max(0.3, poi_px * 0.0001)  # ê¸°ì¡´ ë¡œì§ ìœ ì§€
        bus_poly_df = build_polygon_df(bus_df_for_map, size_px=poi_px_small, lat0=init_lat, zoom=view_state.zoom, shape="triangle")
        bus_layer = pdk.Layer(
            "PolygonLayer",
            data=bus_poly_df,
            get_polygon="polygon",
            filled=True,
            get_fill_color=[0, 0, 0, 220],
            stroked=True,
            get_line_color=[0, 0, 0, 255],
            lineWidthMinPixels=1,
            pickable=True,
            auto_highlight=True,
        )
        layers.append(bus_layer)

    # ì§€í•˜ì²  íˆ´íŒ/ë„í˜•
    if show_subway and subway_df_for_map is not None and not subway_df_for_map.empty:
        for need in ["ì—­ëª…","í˜¸ì„ ","ì—­ë²ˆí˜¸"]:
            if need not in subway_df_for_map.columns:
                subway_df_for_map[need] = ""
        def _normalize_line(v):
            s = str(v).strip()
            if not s: return ""
            if re.fullmatch(r"\d+", s):
                s = f"{int(s)}í˜¸ì„ "
            elif ("í˜¸ì„ " not in s) and not re.search(r"[ê°€-í£]í˜¸ì„ $", s):
                s = f"{s}í˜¸ì„ "
            return s
        def _mk_sub_tip(r):
            line = _normalize_line(r.get("í˜¸ì„ ",""))
            sta  = str(r.get("ì—­ëª…","")).strip()
            no   = str(r.get("ì—­ë²ˆí˜¸","")).strip()
            bits = []
            if line: bits.append(f"í˜¸ì„  : {line}")
            if no:   bits.append(f"ì—­ë²ˆí˜¸ : {no}")
            info = " , ".join(bits)
            return f"ğŸš‡ {sta}\n{info}"
        subway_df_for_map["tooltip"] = subway_df_for_map.apply(_mk_sub_tip, axis=1)

        poi_px = int(np.clip((map_df["pt_size"].median() if ("pt_size" in map_df.columns and not map_df["pt_size"].empty) else marker_px), 6, 32))
        poi_px_small = max(0.3, poi_px * 0.0001)
        subway_poly_df = build_polygon_df(subway_df_for_map, size_px=poi_px_small, lat0=init_lat, zoom=view_state.zoom, shape="square")
        subway_layer = pdk.Layer(
            "PolygonLayer",
            data=subway_poly_df,
            get_polygon="polygon",
            filled=True,
            get_fill_color=[0, 0, 0, 220],
            stroked=True,
            get_line_color=[0, 0, 0, 255],
            lineWidthMinPixels=1,
            pickable=True,
            auto_highlight=True,
        )
        layers.append(subway_layer)

# === ê°€ë¡œ í•œ ì¤„ ìš”ì•½(ê°€ë§¹ì /ë²„ìŠ¤/ì§€í•˜ì²  í‘œì‹œ ê°œìˆ˜) ===
c1, c2, c3 = st.columns(3)

# í‘œì‹œ(Shown)ëŠ” ì‹¤ì œ ì§€ë„ì— ê·¸ë ¤ì§€ëŠ” ê°œìˆ˜ë¡œ ê³„ì‚°
store_total = len(snapshot)
store_shown = len(map_df)

bus_total = len(bus_df) if bus_df is not None else 0
bus_shown = (len(bus_df_for_map) if (show_bus and (bus_df_for_map is not None)) else 0)

subway_total = len(subway_df) if subway_df is not None else 0
subway_shown = (len(subway_df_for_map) if (show_subway and (subway_df_for_map is not None)) else 0)

with c1:
    st.caption(f"ğŸª ê°€ë§¹ì : ì „ì²´ {store_total:,} â†’ í‘œì‹œ {store_shown:,}")
with c2:
    st.caption(f"ğŸšŒ ë²„ìŠ¤ ì •ë¥˜ì¥: ì „ì²´ {bus_total:,} â†’ í‘œì‹œ {bus_shown:,}")
with c3:
    st.caption(f"ğŸš‡ ì§€í•˜ì²  ì—­: ì „ì²´ {subway_total:,} â†’ í‘œì‹œ {subway_shown:,}")

# âœ… ì—¬ê¸°ì„œë¶€í„°ëŠ” ì»¬ëŸ¼ ë¸”ë¡ 'ë°–'(ë“¤ì—¬ì“°ê¸° 0)
TOOLTIP = {"text": "{tooltip}"}
st.pydeck_chart(
    pdk.Deck(
        map_style="https://basemaps.cartocdn.com/gl/positron-gl-style/style.json",
        initial_view_state=view_state,
        layers=layers,
        tooltip=TOOLTIP,
    ),
    use_container_width=True,  # ì „ì²´ í­ ì‚¬ìš©
)

st.markdown('<div class="sep"></div>', unsafe_allow_html=True)

# --------------------------------------------
# ìœ„í—˜ ë‹¨ê³„ ë§¤ì¥ ìˆœìœ„ (ë‹¨ì¼ ì„ íƒ ì²´í¬ë°•ìŠ¤)
# --------------------------------------------
st.subheader("âš ï¸ ìœ„í—˜ ë‹¨ê³„ ë§¤ì¥ ìˆœìœ„")
rank_df = filtered.copy()
if selected_dong:
    rank_df = rank_df[rank_df["í–‰ì •ë™"] == selected_dong]
if selected_category:
    rank_df = rank_df[rank_df["ì—…ì¢…"] == selected_category]

rank_df = filtered.copy()
# ...
order = pd.CategoricalDtype(categories=["ìœ„í—˜","ì£¼ì˜","ê´€ì‹¬","ì•ˆì •"], ordered=True)
if "ìœ„í—˜ë“±ê¸‰" in rank_df.columns:
    rank_df["ìœ„í—˜ë“±ê¸‰"] = rank_df["ìœ„í—˜ë“±ê¸‰"].astype(order)

rank_df = rank_df.sort_values(["ìœ„í—˜ë“±ê¸‰","ìœ„í—˜ë„"], ascending=[True, False]).reset_index(drop=True)


show_cols = [
    "ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸","ê°€ë§¹ì ëª…","í–‰ì •ë™","ì—…ì¢…","ìœ„í—˜ë„","ìœ„í—˜ë“±ê¸‰","íšŒë³µíƒ„ë ¥ì„± ì ìˆ˜",
    "êµí†µì ‘ê·¼ì„± ì ìˆ˜","ê²½ìŸê³¼ì—´","íì—…ì—¬ë¶€","ì„ëŒ€ë£Œ ì ìˆ˜","ì†Œë¹„ì•¡ ì ìˆ˜"
]
show_cols = [c for c in show_cols if c in rank_df.columns]
rank_df = rank_df.sort_values(["ìœ„í—˜ë“±ê¸‰","ìœ„í—˜ë„"], ascending=[True, False]).reset_index(drop=True)

# âœ… í˜„ì¬ ì„ íƒ(ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸)ì„ ì„¸ì…˜ì— ë³´ê´€
if "sel_sid" not in st.session_state:
    st.session_state.sel_sid = None

# í…Œì´ë¸” í‘œì‹œìš© DF ìƒì„±: 'ì„ íƒ'ì€ í˜„ì¬ ì„ íƒëœ í–‰ë§Œ True
rank_df_display = rank_df.copy()
rank_df_display.insert(
    0, "ì„ íƒ",
    rank_df_display["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"].astype(str) == (st.session_state.sel_sid or "")
)

edited = st.data_editor(
    rank_df_display[["ì„ íƒ"] + show_cols],
    use_container_width=True,
    hide_index=True,
    key="rank_editor",
    column_config={
        "ì„ íƒ": st.column_config.CheckboxColumn(
            "ì„ íƒ",
            help="ìƒì„¸ ë¶„ì„í•  ë§¤ì¥ì„ í•œ ê°œ ì„ íƒí•˜ì„¸ìš”",
            default=False
        )
    }
)

# ë‹¨ì¼ ì„ íƒ ê°•ì œ ë¡œì§: ì—¬ëŸ¬ ê°œê°€ Trueì—¬ë„ 'ë§ˆì§€ë§‰ ì˜ë„'ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” í•´ì œ
sel_mask = edited["ì„ íƒ"] == True
if sel_mask.any():
    selected_ids = edited.loc[sel_mask, "ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"].astype(str).tolist()
    prev = st.session_state.sel_sid
    # ì´ì „ ì„ íƒì´ í¬í•¨ë˜ì–´ ìˆê³  2ê°œ ì´ìƒì´ë©´, ì´ì „ ê²ƒ ì œì™¸í•œ ì²« ë²ˆì§¸ë¥¼ ìƒˆ ì„ íƒìœ¼ë¡œ
    if prev in selected_ids and len(selected_ids) > 1:
        new_sel = next((x for x in selected_ids if x != prev), prev)
    else:
        new_sel = selected_ids[0]
    if new_sel != prev:
        st.session_state.sel_sid = new_sel
        try:
            st.rerun()
        except Exception:
            st.experimental_rerun()
else:
    # ëª¨ë‘ í•´ì œë˜ë©´ ì„ íƒ í•´ì œ
    if st.session_state.sel_sid is not None:
        st.session_state.sel_sid = None
        try:
            st.rerun()
        except Exception:
            st.experimental_rerun()

# ì´í›„ ì„¹ì…˜(ë§¤ì¥ ìƒì„¸ ë¶„ì„)ì—ì„œ ì‚¬ìš©í•  ì„ íƒê°’
sel_sid = st.session_state.sel_sid

st.markdown('<div class="sep"></div>', unsafe_allow_html=True)


# --------------------------------------------
# ë§¤ì¥ ìƒì„¸ ë¶„ì„ (ì„ íƒ ë§¤ì¥) â€” ìƒˆ êµ¬ì„± (2ì„¹ì…˜)
# --------------------------------------------
st.subheader("ğŸ” ì„ íƒ ë§¤ì¥ ìƒì„¸ ë¶„ì„")

if sel_sid is None:
    st.info("ìœ„ì˜ **ìœ„í—˜ ë‹¨ê³„ ë§¤ì¥ ìˆœìœ„** í‘œì—ì„œ ë§¤ì¥ì„ í•˜ë‚˜ ì„ íƒí•˜ë©´ ìƒì„¸ ë¶„ì„ì´ í‘œì‹œë©ë‹ˆë‹¤.")
else:
    # ì„ íƒ ë§¤ì¥ ë‹¨ì¼ í–‰ í™•ë³´
    store_row = rank_df[rank_df["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"].astype(str) == sel_sid]
    if store_row.empty:
        st.info("ì„ íƒí•œ ë§¤ì¥ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.write(f"**{store_row.iloc[0].get('ê°€ë§¹ì ëª…','')}** / {store_row.iloc[0].get('í–‰ì •ë™','')} / {store_row.iloc[0].get('ì—…ì¢…','')}")

        # --- ì•ˆì „ ê°€ë“œ: ì„ íƒ ë§¤ì¥ ì‹œê³„ì—´ í™•ë³´ ---
        ts = final_df[final_df["ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸"].astype(str) == sel_sid].copy()
        if ts.empty or ("ê¸°ì¤€ë…„ì›”" not in ts.columns):
            st.info("í•´ë‹¹ ë§¤ì¥ì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 'ê¸°ì¤€ë…„ì›”' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ===============================
            # ì„¹ì…˜ 1) 2ë¶„í• 
            #   - ì™¼ìª½: 6ê°œ ì§€í‘œì˜ 'ë¶„ê¸°ë³„' ì¶”ì´ (ë¼ì¸)
            #   - ì˜¤ë¥¸ìª½: ë ˆì´ë”(ìµœì‹  ë¶„ê¸°)
            # ===============================

            # ê¸°ì¤€ë…„ì›” â†’ ë‚ ì§œ ë³€í™˜(YYYY-MM/ YYYYMM ëª¨ë‘ ëŒ€ì‘)
            def _parse_ym(val):
                s = str(val)
                if "-" in s:  # YYYY-MM
                    s2 = s + "-01" if len(s) == 7 else s
                else:         # YYYYMM
                    s2 = (s[:4] + "-" + s[4:6] + "-01") if len(s) >= 6 else s
                return pd.to_datetime(s2, errors="coerce")

            ts_q = ts.copy()
            ts_q["_date"] = ts_q["ê¸°ì¤€ë…„ì›”"].apply(_parse_ym)
            ts_q = ts_q.dropna(subset=["_date"]).sort_values("_date")

            # ì‚¬ìš©í•  6ê°œ ì§€í‘œ(ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
            six_metrics = [
                "ê³ ê°ë‹¤ì–‘ì„±_ì ìˆ˜",
                "ì„ëŒ€ë£ŒëŒ€ë¹„ë§¤ì¶œ_ì ìˆ˜",
                "ê°ë‹¨ê°€_ì•ˆì •ì„±_ì ìˆ˜",
                "ê³ ê°ì¸êµ¬_ì í•©ë„_ì ìˆ˜",
                "ê°€ë§¹ì ì…ì§€ì ìˆ˜",
                "ì†Œë¹„ì•¡ëŒ€ë¹„ë§¤ì¶œì ìˆ˜",
            ]
            six_metrics = [c for c in six_metrics if c in ts_q.columns]

            col_l, col_r = st.columns([2, 1])

            # --- (ì™¼ìª½) ë¶„ê¸°ë³„ ë¼ì¸ ---
            if six_metrics:
                # ë¶„ê¸° í‚¤
                qkey = ts_q["_date"].dt.to_period("Q")
                agg_dict = {c: "mean" for c in six_metrics}
                qdf = ts_q.groupby(qkey).agg(agg_dict).reset_index(names="ë¶„ê¸°")

                # ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¼ë²¨
                def _pretty_quarter(p):
                    s = str(p)  # e.g., '2024Q3'
                    try:
                        year = int(s[:4]); q = int(s[-1])
                        return f"{year}ë…„ {q}ë¶„ê¸°"
                    except Exception:
                        return s

                qdf["ë¶„ê¸°ë¼ë²¨"] = qdf["ë¶„ê¸°"].apply(_pretty_quarter)

                if not qdf.empty:
                    q_long = qdf.melt(
                        id_vars=["ë¶„ê¸°", "ë¶„ê¸°ë¼ë²¨"],
                        value_vars=six_metrics,
                        var_name="ì§€í‘œ",
                        value_name="ê°’",
                    )
                    fig_quarter_lines = px.line(
                        q_long,
                        x="ë¶„ê¸°ë¼ë²¨",
                        y="ê°’",
                        color="ì§€í‘œ",
                        markers=True,
                        title="ë¶„ê¸°ë³„ ì§€í‘œ ì¶”ì´(í‰ê· )",
                        hover_data={"ë¶„ê¸°ë¼ë²¨": False, "ì§€í‘œ": True, "ê°’": ":.1f"},
                        labels={"ê°’": "ì ìˆ˜(0~100)"}
                    )

                    # âœ… xì¶• ë¼ë²¨ ì—†ì• ê¸°
                    fig_quarter_lines.update_xaxes(title_text="")

                    # ë²”ë¡€ ìœ„ì¹˜ ì¡°ì •
                    fig_quarter_lines.update_layout(
                        height=360,
                        margin=dict(l=10, r=10, t=50, b=110),   # ğŸ”½ ë²”ë¡€ ìë¦¬ í™•ë³´
                        legend=dict(
                            orientation="h",
                            x=0.5, xanchor="center",            # ê°€ë¡œ ì¤‘ì•™ ì •ë ¬
                            y=-0.25, yanchor="top",             # ğŸ”½ ë” ì•„ë˜ë¡œ ë‚´ë¦¼
                            bgcolor="rgba(0,0,0,0)"
                        ),
                        legend_title_text=""
                    )
                    # xì¶• ë¼ë²¨ ìˆ¨ê¹€ (tickì€ ê·¸ëŒ€ë¡œ)
                    fig_quarter_lines.update_xaxes(title_text="")
                    # ì¶• ì—¬ë°± ìë™ ì¡°ì •(ì„ íƒ)
                    fig_quarter_lines.update_xaxes(automargin=True)
                    fig_quarter_lines.update_yaxes(automargin=True)

                    col_l.plotly_chart(fig_quarter_lines, use_container_width=True)

                else:
                    col_l.info("ë¶„ê¸°ë³„ë¡œ ì§‘ê³„í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                col_l.info("ë¶„ê¸°ë³„ ì¶”ì´ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")

            # --- (ì˜¤ë¥¸ìª½) ìµœì‹  ë¶„ê¸° ë ˆì´ë” ---
            if six_metrics and 'qdf' in locals() and not qdf.empty:
                latest_q = qdf.iloc[-1]
                radar_vals = [
                    float(latest_q.get(c, np.nan)) if pd.notna(latest_q.get(c, np.nan)) else None
                    for c in six_metrics
                ]
                categories = [c.replace("_", "<br>") for c in six_metrics]

                fig_radar = go.Figure()
                fig_radar.add_trace(go.Scatterpolar(
                    r=radar_vals,
                    theta=categories,
                    fill="toself",
                    name="ìµœì‹  ë¶„ê¸°"
                ))
                fig_radar.update_layout(
                    title=f"ë ˆì´ë”(ìµœì‹  ë¶„ê¸°: {latest_q['ë¶„ê¸°ë¼ë²¨']})",
                    polar=dict(radialaxis=dict(visible=True, range=[0, 100])),
                    showlegend=False,
                    height=360,
                    margin=dict(l=10, r=10, t=50, b=10),
                )
                col_r.plotly_chart(fig_radar, use_container_width=True)
            else:
                col_r.info("ë ˆì´ë”ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ìµœì‹  ë¶„ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown('<div class="sep"></div>', unsafe_allow_html=True)

            # ===============================
            # ì„¹ì…˜ 2) ì „ì²´ í­ â€” ì›”ë³„ 'ë§¤ì¶œ' ì¶”ì´
            # ===============================
            sales_candidates = ["ë§¤ì¶œê¸ˆì•¡", "ë§¤ì¶œêµ¬ê°„", "ì´ë§¤ì¶œ", "ë§¤ì¶œ", "ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„", "ë§¤ì¶œê±´ìˆ˜"]
            sales_col = next((c for c in sales_candidates if c in ts_q.columns), None)

            if sales_col is not None:
                y_series = pd.to_numeric(ts_q[sales_col], errors="coerce")
                y_is_numeric = y_series.notna().any()

                # âœ… ì›” ë¼ë²¨ í¬ë§·: '2023ë…„ 1ì›”' ì‹ìœ¼ë¡œ
                ts_q["_label"] = ts_q["_date"].dt.strftime("%Yë…„ %#mì›”")  # ìœˆë„ìš°ë©´ %-m ëŒ€ì‹  %#m ì‚¬ìš©

                fig_sales = px.line(
                    ts_q,
                    x="_label",
                    y=sales_col,
                    markers=True,
                    title=f"ì›”ë³„ {sales_col} ì¶”ì´",
                    labels={"_label": "ê¸°ì¤€ë…„ì›”", sales_col: ("ë§¤ì¶œêµ¬ê°„" if y_is_numeric else sales_col)},
                )

                # âœ… ì „ì²´ ê¸°ê°„ì„ 2023.1 ~ 2024.12ë¡œ ê³ ì •
                start_date = pd.Timestamp("2023-01-01")
                end_date   = pd.Timestamp("2024-12-31")

                # Plotly layout ì„¤ì •
                fig_sales.update_layout(
                    height=360,
                    margin=dict(l=10, r=10, t=50, b=10),
                    xaxis=dict(
                        title="ê¸°ì¤€ë…„ì›”",
                        tickmode="array",
                        tickvals=ts_q["_label"].unique().tolist(),
                        tickangle=45
                    ),
                    yaxis=dict(
                        title=("ë§¤ì¶œêµ¬ê°„" if y_is_numeric else sales_col),
                        range=[1, 6],     # âœ… Yì¶• 1~6 ê³ ì •
                        dtick=1
                    )
                )

                st.plotly_chart(fig_sales, use_container_width=True)
            else:
                st.info("ì›” ë‹¨ìœ„ ë§¤ì¶œ ì¶”ì´ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì˜ˆ: 'ë§¤ì¶œê¸ˆì•¡', 'ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„' ë“±)")

